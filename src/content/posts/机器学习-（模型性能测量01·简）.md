---
title: 机器学习-（模型性能测量01·简）
description: 交叉验证
pubDate: 2025-07-05
---

## 简单分割测试集与验证集缺点

数据有随机性，我们选择测试集和训练集也有随机性。

假如一个数据集的80%做训练集，20%做测试集。结果模型误差较小，可能是因为我们选择的这些测试集刚好比较符合，那么换其他测试集可能表现就不好了。

为了尽可能的覆盖更多随机性，我们可以选择增加测试集比例，但是这会导致训练集比例减少，就会导致模型拟合效果不够好。

所以，引入了交叉验证。

## Cross-Validation 交叉验证

### 概述

例如，将数据集分割成5部分，称作5个**“folds”**

对每个**“folds”**都进行一轮实验。

第一次实验中，将第一个**fold**作为维持集用于测试模型，其余四部分用于训练。

第二次实验中，将第二个**fold**作为维持集用于测试模型，其余四部分用于训练。

以此类推，共进行5轮，这样我们就相当于使用了全部的数据集用于测试模型，以期达到最好的测试效果。

### 使用交叉验证的时机

交叉验证可以更准确地衡量模型质量，这在做出大量建模决策时尤为重要。但是，可能需要更长的运行时间，因为它会估算多个模型（每个**fold**一个模型）。

所以：

- 小数据集，应该使用。
- 大数据集，根据情况决定，一般来说，大数据集的20%留出的测试集已经很大了，能够较为准确的衡量模型质量。可以不使用，但是如果设备性能强，对大数据集交叉验证的时间开销可以接受的话，也可以交叉验证。

主要是成本和衡量准确度的权衡。

## 代码实现

### 加载数据

```python
import pandas as pd

data = pd.read_csv('../input/melbourne-housing-snapshot/melb_data.csv')

cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']
X = data[cols_to_use]

y = data.Price
```

### 定义管道

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),
                              ('model', RandomForestRegressor(n_estimators=50,
                                                              random_state=0))
                             ])
```

### 交叉验证

```python
from sklearn.model_selection import cross_val_score

scores = -1 * cross_val_score(my_pipeline, X, y,
                              cv=5,
                              scoring='neg_mean_absolute_error')
print("MAE scores:\n", scores)
```

cross_val_score函数可以获得交叉验证分数

```python
cross_val_score(
    estimator,          # 模型（如本例中使用管道）
    X,                  # 特征数据
    y=None,             # 目标变量（分类标签或回归值）
    scoring=None,       # 评分器（本例中使用的属于str（字符串名称评分器）通过名称指定）
    cv=None,            # 交叉验证折叠数（默认 5）或自定义分割器
    n_jobs=None,        # 并行计算的 CPU 核心数（-1 表示使用所有核心）
    verbose=0,          # 日志详细程度
    fit_params=None,    # 传递给模型训练的额外参数
    pre_dispatch='2*n_jobs'  # 控制并行任务的预调度
)
```

最后用交叉验证得分的平均值评估模型性能

```python
print("Average MAE score (across experiments):")
print(scores.mean())
```

